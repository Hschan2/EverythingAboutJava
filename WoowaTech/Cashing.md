# Caching (캐싱)

## 캐시
<b>캐시</b>는 용어적으로 물건을 일시적으로 저장하고 보관하기 위해 사용하는 곳을 의미한다. 기술적으로 자주 필요한 데이터나 값의 복사본을 일시적으로 저장하고 보관하기 위해 사용하는 곳을 의미한다.   

<b>캐싱</b>은 위의 캐시를 사용하는 것을 의미한다.   

## CPU와 메모리 간 성능 차이
CPU는 시간이 지날수록 속도를 빠르게 개발하지만 메모리는 용량을 키우는 것에 집중할 뿐 속도에 집중하지 않는다. 그래서 시간이 흐를수록 둘의 성능 차이가 커진다.   

* CPU는 데이터 처리를 위해 메모리와 끊임없이 데이터를 주고받는 구조
* 메모리가 CPU의 데이터 처리 속도를 쫓아가지 못함
* CPU가 메모리를 기다려야 하는 병목현상 발생   

위의 병목현상을 방지하기 위해 CPU와 RAM(메인 메모리) 사이에 캐시 메모리를 둔다.   

* 캐시 메모리
    * 크기 작음
    * 속도 빠름
    * 재사용 가능성이 높고 데이터 복사본을 저장해둔 후 CPU가 요청하는 데이터를 바로 전달   

캐시 메모리는 한 셀당 트랜지스터가 6개로 구성되어 있으며, 물리적으로 차지하는 면적 또한 캐시 메모리가 크기 때문에 비용이 크다. 그래서 메인 메모리로 사용하거나 양을 늘리는 것은 어려움이 따른다.   

캐싱 메모리를 포함한 구조는 아래와 같다.
```
CPU Registers - LEVEL 1 (빠름, 비쌈)
Cache Memory - LEVEL 2
Main Memory (RAM) - LEVEL 3
Secondary Memory - LEVEL 4 (느림, 저렴)
```
이와 같은 구조는 캐싱을 이용하여 빠르고 작은 메모리와 크고 느린 메모리의 장점을 조합해서 크고 빠른 메모리처럼 행동하도록 만드는 것을 의미한다.   

## 캐시 동작 원리 - 데이터 지역성의 원리
* 데이터 지역성의 원리란 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 의미한다.
* 한 번 참조된 변수는 이후 다시 참조될 가능성이 높아 어떤 데이터에 접근할 때, 그 데이터 근처에 있는 다른 데이터도 참조될 가능성이 높다.   

### 시간 지역성
* 특정 데이터가 한 번 접근되었을 경우, 가까운 미래에 다시 한 번 데이터에 접근할 가능성이 높은 것을 말한다.
* 메모리 상의 같은 주소에 여러 차례 읽기와 쓰기를 수행할 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성을 높일 수 있다.
* For, While문의 조건 변수 i   

### 공간 지역성
* 특정 데이터와 가까운 주소가 순서대로 접근되는 경우를 말한다.
* 한 메모리 주소에 접근할 때 해당 주소뿐 만 아니라 해당 블록을 전부 캐시에 가져온다.
* 이 때, 메모리 주소를 오름차순이나 내림차순으로 접근한다면 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상될 수 있다.
* 배열은 순서대로 접근할 가능성이 크다.   

### 데이터 지역성 코드 예시
```
for (i = 0; i < 3; i++) {
    data[i+1] = data[i] + 1;
}

실행 결과

data[1] = data[0] + 1;
data[2] = data[1] + 1;
data[3] = data[2] + 1;
```
* 변수 i를 선언 후 재접근: 시간 지역성
* data[0]에 접근 -> data[1]에 접근 -> data[2]에 접근: 공간 지역성   

## 캐시 히트와 캐시 미스
* CPU가 데이터 요청 시, 캐시 메모리가 해당 데이터를 가지고 있다면 캐시 히트(캐시 적중)을 말한다.
* 해당 데이터가 없어서 메인 메모리에서 가져와야 한다면 캐시 미스를 말한다.   

## 캐시 메모리 쓰기와 캐시 일관성
* CPU에서 데이터를 읽는 동작이 아니라 입력하는 동작이 발생하고 데이터를 변경할 주소가 캐싱된 상태라면 메모리이ㅡ 데이터가 업데이트 되는 대신 캐시의 데이터가 업데이트 한다.
* 메인 메모리를 업데이트 하기 위해 메인 메모리를 업데이트하는 시점에 따라 정책이 두 가지로 나뉜다. 즉, 캐시 히트 상태에서 데이터 스기 동작이 발생한다면 두 가지 정책이 있다는 것이다.   

### Write Through 정책
* 메인 메모리를 바로 업데이트
* 단순하고 캐시와 메인 메모리의 일관성을 유지할 수 있지만, 매번 바꿔줘야 되므르 느림   

### Write Back 정책
* 캐시만 업데이트 하다가 업데이트 된 데이터가 캐시에서 빠지게 될 때, 메인 메모리를 업데이트
* 속도가 빠르지만 캐시와 메모리가 서로 값이 다른 경우가 발생하는 경우가 존재
* 데이터 변경을 확인하기 위해 캐시 블록마다 Dirty 비트를 추가, 데이터가 변경되었다면 1로 변경. 이 후, 해당 블록이 교체될 때 Dirty 비트가 1이라면 메모리의 데이터를 변경

## 정리
* 캐싱: 캐시에 데이터나 계산된 결과 값의 복사본을 저장해 둠으로써 전체적인 처리 속도 향상
    * 데이터에 직접적으로 접근하는 데 걸리는 시간이 오래 걸릴 때
    * 필요한 값을 얻기 위해 계산하는 과정을 생략하고 싶을 때
    * 반복적으로 동일한 결과를 돌려주는 경우 (이미지나 썸네일 등)

캐싱은 복사본을 이용하는 것이기 때문에 복사본과 원본이 달라지는 경우가 생길 수 있기 때문에 일관성 유지에 유의가 필요하다.

[Caching (캐싱)](https://www.youtube.com/watch?v=JBFT4KyEvoY)